{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "11.3\n",
      "cuda\n",
      "11.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/michele/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/michele/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "\n",
    "from modelAB import *\n",
    "from modelCD import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PAD_TOKEN = '<pad>'\n",
    "EN_TRAIN_PATH = \"./../../data/EN/train.json\"\n",
    "EN_DEV_PATH = \"./../../data/EN/dev.json\"\n",
    "BERT_PATH = \"./../../model/bert-base-cased\"\n",
    "#BERT_PATH = \"./model/bert-base-cased\"\n",
    "VERBATLAS_PATH = \"./VerbAtlas/VerbAtlas\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def read_dataset(path: str):\n",
    "    with open(path) as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    sentences, labels = {}, {}\n",
    "    for sentence_id, sentence in dataset.items():\n",
    "        sentence_id = sentence_id\n",
    "        sentences[sentence_id] = {\n",
    "            \"words\": sentence[\"words\"],\n",
    "            \"lemmas\": sentence[\"lemmas\"],\n",
    "            \"pos_tags\": sentence[\"pos_tags\"],\n",
    "            \"dependency_heads\": [int(head) for head in sentence[\"dependency_heads\"]],\n",
    "            \"dependency_relations\": sentence[\"dependency_relations\"],\n",
    "            \"predicates\": sentence[\"predicates\"],\n",
    "        }\n",
    "\n",
    "        labels[sentence_id] = {\n",
    "            \"predicates\": sentence[\"predicates\"],\n",
    "            \"roles\": {int(p): r for p, r in sentence[\"roles\"].items()}\n",
    "            if \"roles\" in sentence\n",
    "            else dict(),\n",
    "        }\n",
    "\n",
    "    return sentences, labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nearly_stopping = pl.callbacks.EarlyStopping(\\n    monitor=\\'val_f1\\',  # the value that will be evaluated to activate the early stopping of the model.\\n    patience=5,\\n    # the number of consecutive attempts that the model has to raise (or lower depending on the metric used) to raise the \"monitor\" value.\\n    verbose=True,  # whether to log or not information in the console.\\n    mode=\\'max\\',  # wheter we want to maximize (max) or minimize the \"monitor\" value.\\n)\\n\\ncheck_point_callback = pl.callbacks.ModelCheckpoint(\\n    monitor=\\'val_f1\\',  # the value that we want to use for model selection.\\n    verbose=True,  # whether to log or not information in the console.\\n    save_top_k=1,  # the number of checkpoints we want to store.\\n    mode=\\'max\\',  # wheter we want to maximize (max) or minimize the \"monitor\" value.\\n    filename=\\'modelAB_{epoch}-{val_f1:.4f}\\'\\n    # the prefix on the checkpoint values. Metrics store by the trainer can be used to dynamically change the name.\\n)\\n\\nab_dm = PredicatesDataModule(\\n    verbAtlas_path=VERBATLAS_PATH,\\n    data_train_path=EN_TRAIN_PATH,\\n    data_dev_path=EN_DEV_PATH,\\n    data_test_path=EN_DEV_PATH,\\n    batch_size=8\\n)\\n\\nab_classifier = AB_Model(language=\"en\", hidden2=200, lstm_layers=1, bidirectional=False, p=0.5).to(device)\\n\\n# the PyTorch Lightning Trainer\\ntrainer = pl.Trainer(\\n    max_epochs=20,  # maximum number of epochs.\\n    gpus=1,  # the number of gpus we have at our disposal.\\n    callbacks=[early_stopping, check_point_callback]  # the callback we want our trainer to use.\\n)\\n\\n# and finally we can let the \"trainer\" fit the amazon reviews classifier.\\ntrainer.fit(model=ab_classifier, datamodule=ab_dm)\\n\\nmodel_path = \"../../model/modelAB.ckpt\"\\n#classifier = AB_Model.load_from_checkpoint(model_path, language=\"en\").to(device)\\n\\n\\n\\n\\nsentences, labels = read_dataset(EN_DEV_PATH)\\n\\nfor idx, key in enumerate(sentences):\\n    prediction = ab_classifier.predict(sentences[key])\\n    lab = labels[key][\"predicates\"]\\n    print(\"PREDICTED\", len(prediction), prediction)\\n    print(\"GROUND TRUTH\", len(lab), lab)\\n#'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "early_stopping = pl.callbacks.EarlyStopping(\n",
    "    monitor='val_f1',  # the value that will be evaluated to activate the early stopping of the model.\n",
    "    patience=5,\n",
    "    # the number of consecutive attempts that the model has to raise (or lower depending on the metric used) to raise the \"monitor\" value.\n",
    "    verbose=True,  # whether to log or not information in the console.\n",
    "    mode='max',  # wheter we want to maximize (max) or minimize the \"monitor\" value.\n",
    ")\n",
    "\n",
    "check_point_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_f1',  # the value that we want to use for model selection.\n",
    "    verbose=True,  # whether to log or not information in the console.\n",
    "    save_top_k=1,  # the number of checkpoints we want to store.\n",
    "    mode='max',  # wheter we want to maximize (max) or minimize the \"monitor\" value.\n",
    "    filename='modelAB_{epoch}-{val_f1:.4f}'\n",
    "    # the prefix on the checkpoint values. Metrics store by the trainer can be used to dynamically change the name.\n",
    ")\n",
    "\n",
    "ab_dm = PredicatesDataModule(\n",
    "    verbAtlas_path=VERBATLAS_PATH,\n",
    "    data_train_path=EN_TRAIN_PATH,\n",
    "    data_dev_path=EN_DEV_PATH,\n",
    "    data_test_path=EN_DEV_PATH,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "ab_classifier = AB_Model(language=\"en\", hidden2=200, lstm_layers=1, bidirectional=False, p=0.5).to(device)\n",
    "\n",
    "# the PyTorch Lightning Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,  # maximum number of epochs.\n",
    "    gpus=1,  # the number of gpus we have at our disposal.\n",
    "    callbacks=[early_stopping, check_point_callback]  # the callback we want our trainer to use.\n",
    ")\n",
    "\n",
    "# and finally we can let the \"trainer\" fit the amazon reviews classifier.\n",
    "trainer.fit(model=ab_classifier, datamodule=ab_dm)\n",
    "\n",
    "model_path = \"../../model/modelAB.ckpt\"\n",
    "#classifier = AB_Model.load_from_checkpoint(model_path, language=\"en\").to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sentences, labels = read_dataset(EN_DEV_PATH)\n",
    "\n",
    "for idx, key in enumerate(sentences):\n",
    "    prediction = ab_classifier.predict(sentences[key])\n",
    "    lab = labels[key][\"predicates\"]\n",
    "    print(\"PREDICTED\", len(prediction), prediction)\n",
    "    print(\"GROUND TRUTH\", len(lab), lab)\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../../model/bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at ../../model/bert-base-cased and are newly initialized: ['bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.value.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type             | Params\n",
      "------------------------------------------------\n",
      "0 | classifier | Sequential       | 159 K \n",
      "1 | loss_fn    | CrossEntropyLoss | 0     \n",
      "2 | f1         | F1Score          | 0     \n",
      "3 | bert       | BertModel        | 136 M \n",
      "------------------------------------------------\n",
      "136 M     Trainable params\n",
      "0         Non-trainable params\n",
      "136 M     Total params\n",
      "547.347   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1572a429e95f4441804a99c840f9dc12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michele/anaconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/michele/anaconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/home/michele/anaconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f296b78e1e34bec89261d0f009c0629"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c301016de61448f284a3100966d1682e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michele/anaconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 3. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "Metric val_f1 improved. New best score: 0.926\n",
      "Epoch 0, global step 790: val_f1 reached 0.92618 (best 0.92618), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=0-val_f1=0.9262.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "921c88e8cc6044a39c28efdd797296f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.009 >= min_delta = 0.0. New best score: 0.935\n",
      "Epoch 1, global step 1581: val_f1 reached 0.93533 (best 0.93533), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=1-val_f1=0.9353.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9036efc39cdb494e87d7eeb254f9390e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.004 >= min_delta = 0.0. New best score: 0.939\n",
      "Epoch 2, global step 2372: val_f1 reached 0.93935 (best 0.93935), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=2-val_f1=0.9394.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3dcb28949fb4d238372da12b7c72113"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.003 >= min_delta = 0.0. New best score: 0.942\n",
      "Epoch 3, global step 3163: val_f1 reached 0.94188 (best 0.94188), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=3-val_f1=0.9419.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e951825e3ac4d8394beb38cf17be9d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.002 >= min_delta = 0.0. New best score: 0.944\n",
      "Epoch 4, global step 3954: val_f1 reached 0.94398 (best 0.94398), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=4-val_f1=0.9440.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "187d46cc79274eb79206e3181862507b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.001 >= min_delta = 0.0. New best score: 0.945\n",
      "Epoch 5, global step 4745: val_f1 reached 0.94511 (best 0.94511), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=5-val_f1=0.9451.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4193784f1de546aaa12ad53fa01c13c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.001 >= min_delta = 0.0. New best score: 0.946\n",
      "Epoch 6, global step 5536: val_f1 reached 0.94597 (best 0.94597), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=6-val_f1=0.9460.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fdb8748d8f084476bd2939a900caffd1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.001 >= min_delta = 0.0. New best score: 0.947\n",
      "Epoch 7, global step 6327: val_f1 reached 0.94691 (best 0.94691), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=7-val_f1=0.9469.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6cc4e32377e441b0b3e1c0adab281afe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.001 >= min_delta = 0.0. New best score: 0.948\n",
      "Epoch 8, global step 7118: val_f1 reached 0.94752 (best 0.94752), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=8-val_f1=0.9475.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "348446e04d1a4ac49b93f61d98342e63"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.001 >= min_delta = 0.0. New best score: 0.949\n",
      "Epoch 9, global step 7909: val_f1 reached 0.94873 (best 0.94873), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=9-val_f1=0.9487.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c4f85569a6b4d2da5fb09eae9c8b2a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.001 >= min_delta = 0.0. New best score: 0.950\n",
      "Epoch 10, global step 8700: val_f1 reached 0.94954 (best 0.94954), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=10-val_f1=0.9495.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a01dee149394af9ab212d411d78dd10"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 9491: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "761907d0e66c492581c63d3e853bfaa0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 10282: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8f0c742f04f479883ba0394a0fed335"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.001 >= min_delta = 0.0. New best score: 0.950\n",
      "Epoch 13, global step 11073: val_f1 reached 0.95030 (best 0.95030), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=13-val_f1=0.9503.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b516aee545c411faeb52fd027da5465"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.001 >= min_delta = 0.0. New best score: 0.951\n",
      "Epoch 14, global step 11864: val_f1 reached 0.95081 (best 0.95081), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=14-val_f1=0.9508.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5a3978c6b74467a95f77fb692939a14"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.000 >= min_delta = 0.0. New best score: 0.951\n",
      "Epoch 15, global step 12655: val_f1 reached 0.95127 (best 0.95127), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=15-val_f1=0.9513.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9aaa23ccbfd84659bd3641f2b75444fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 13446: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de3a2d7cf7074a37bd1b4ba1d1ec1a28"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.000 >= min_delta = 0.0. New best score: 0.952\n",
      "Epoch 17, global step 14237: val_f1 reached 0.95166 (best 0.95166), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=17-val_f1=0.9517.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8db0613560c840858e505366e461c24d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.000 >= min_delta = 0.0. New best score: 0.952\n",
      "Epoch 18, global step 15028: val_f1 reached 0.95178 (best 0.95178), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=18-val_f1=0.9518.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28dabf77096444a499815c2d88c77b44"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 15819: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57530d56af824c579097f751f693f5ef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 16610: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "978ceffe803b4240aef5c695bee08508"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.001 >= min_delta = 0.0. New best score: 0.952\n",
      "Epoch 21, global step 17401: val_f1 reached 0.95244 (best 0.95244), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=21-val_f1=0.9524.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7e1c0acf22a4eb7aef6d019b9829d8a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.000 >= min_delta = 0.0. New best score: 0.953\n",
      "Epoch 22, global step 18192: val_f1 reached 0.95261 (best 0.95261), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=22-val_f1=0.9526.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0af7557ae40b4b98b47385759b60135e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 18983: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4015ee6d0dff462fb6c1e5f8517fa3da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.000 >= min_delta = 0.0. New best score: 0.953\n",
      "Epoch 24, global step 19774: val_f1 reached 0.95289 (best 0.95289), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=24-val_f1=0.9529.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d32ba3650f1d469eb6aa06f2173ff786"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 20565: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a3a5db511f04ed18b255e83d678974c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.000 >= min_delta = 0.0. New best score: 0.953\n",
      "Epoch 26, global step 21356: val_f1 reached 0.95291 (best 0.95291), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=26-val_f1=0.9529.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd7fdd42004e4340bba57f4328468a92"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.000 >= min_delta = 0.0. New best score: 0.953\n",
      "Epoch 27, global step 22147: val_f1 reached 0.95297 (best 0.95297), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=27-val_f1=0.9530.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d1dba67960bc4e2cab54e08ca2742a43"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 22938: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cf3f990bf100482cac3717bcf383d4da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 23729: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4cf5f5ebbc1941bd84011e44a1981092"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.000 >= min_delta = 0.0. New best score: 0.953\n",
      "Epoch 30, global step 24520: val_f1 reached 0.95336 (best 0.95336), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=30-val_f1=0.9534.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7118adbcb0b84fb1953705e10db989a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31, global step 25311: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c32096a6c9344f4f8d8ddfc61fa797aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.000 >= min_delta = 0.0. New best score: 0.953\n",
      "Epoch 32, global step 26102: val_f1 reached 0.95348 (best 0.95348), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=32-val_f1=0.9535.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "820b5be40edb4510bb5f60feae9abcbb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33, global step 26893: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d92e52d2b9a44567ab757078bf8a99c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34, global step 27684: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5d8f4bcc1554c788d6dd10a340752e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.000 >= min_delta = 0.0. New best score: 0.954\n",
      "Epoch 35, global step 28475: val_f1 reached 0.95363 (best 0.95363), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=35-val_f1=0.9536.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f0013ee45d6944ee8e41e621f0f7ef87"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36, global step 29266: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0274af00f6c9467f91017376f5d4f0df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37, global step 30057: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23a56d26ccbe4df6a86347e7a1fdfd50"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.000 >= min_delta = 0.0. New best score: 0.954\n",
      "Epoch 38, global step 30848: val_f1 reached 0.95383 (best 0.95383), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=38-val_f1=0.9538.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b04824655f4e4ef19fed6910fad0a357"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 31639: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ab3502fc5714724b1e9f31fd184d165"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40, global step 32430: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "808f08b335c34fc98b71a06ed6b11dfd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.000 >= min_delta = 0.0. New best score: 0.954\n",
      "Epoch 41, global step 33221: val_f1 reached 0.95386 (best 0.95386), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=41-val_f1=0.9539.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc2c0c671d2844da9cd4c6d53a945028"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42, global step 34012: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "535d384c513340d9b445e542f07f8044"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43, global step 34803: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "328fc3e322af41448973a2dd026e12fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.000 >= min_delta = 0.0. New best score: 0.954\n",
      "Epoch 44, global step 35594: val_f1 reached 0.95404 (best 0.95404), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=44-val_f1=0.9540.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8fc809a059a47749a557ab712aa59fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45, global step 36385: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48d0c7c3755b4baebb4e0151438681a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.000 >= min_delta = 0.0. New best score: 0.954\n",
      "Epoch 46, global step 37176: val_f1 reached 0.95418 (best 0.95418), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=46-val_f1=0.9542.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5dcf4794135145dba2616f4f8a75b7a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47, global step 37967: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7829989afa749f790cafdb99bed5d8f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48, global step 38758: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d824615a4563460aa5c4bdd9297be5b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 39549: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e3d8b8d6c7bc48a39334774efe370849"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.000 >= min_delta = 0.0. New best score: 0.954\n",
      "Epoch 50, global step 40340: val_f1 reached 0.95426 (best 0.95426), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=50-val_f1=0.9543.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cf80c5ccbf154c37a3fde348b009790b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51, global step 41131: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15d5505cca774eeea1e16655af9c24fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52, global step 41922: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9cc6c3940d41421d81106be88ee57911"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53, global step 42713: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0510bb1785b648a7a8febab1fb60e4f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54, global step 43504: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca9a7c392b67468f88bdb6f8712c7cec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved by 0.000 >= min_delta = 0.0. New best score: 0.954\n",
      "Epoch 55, global step 44295: val_f1 reached 0.95450 (best 0.95450), saving model to \"/home/michele/PycharmProjects/nlp2022-hw2-main/hw2/stud/lightning_logs/version_35/checkpoints/model_CDepoch=55-val_f1=0.9545.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d48dd3dc79740cba2c1c8f26fdb1f90"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56, global step 45086: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a5c308f1a034aacb201c1469b97b532"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57, global step 45877: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a826d561f884c55a264692bb853103e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58, global step 46668: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47727918609b4d5c8d83bab9aee40f02"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59, global step 47459: val_f1 was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4037b35961c046a3ae721b370b67791b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_f1 did not improve in the last 5 records. Best score: 0.954. Signaling Trainer to stop.\n",
      "Epoch 60, global step 48250: val_f1 was not in top 1\n",
      "Some weights of the model checkpoint at ../../model/bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at ../../model/bert-base-cased and are newly initialized: ['bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.value.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 41>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     38\u001B[0m sentences,labels \u001B[38;5;241m=\u001B[39m read_dataset(EN_DEV_PATH)\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx,key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(sentences):\n\u001B[0;32m---> 42\u001B[0m     prediction \u001B[38;5;241m=\u001B[39m \u001B[43mcd_classifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43msentences\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mroles\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     43\u001B[0m     lab \u001B[38;5;241m=\u001B[39m labels[key][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mroles\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPREDICTED\u001B[39m\u001B[38;5;124m\"\u001B[39m,prediction)\n",
      "File \u001B[0;32m~/PycharmProjects/nlp2022-hw2-main/hw2/stud/modelCD.py:399\u001B[0m, in \u001B[0;36mCD_Model.predict\u001B[0;34m(self, sentence, predicates)\u001B[0m\n\u001B[1;32m    397\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m batches:\n\u001B[1;32m    398\u001B[0m     X, X_len, segment_ids, y, predicate_position, attention_mask, around_predicate, ids \u001B[38;5;241m=\u001B[39m batch\n\u001B[0;32m--> 399\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43mX_len\u001B[49m\u001B[43m,\u001B[49m\u001B[43msegment_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43mpredicate_position\u001B[49m\u001B[43m,\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43maround_predicate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    400\u001B[0m     preds \u001B[38;5;241m=\u001B[39m output[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mflat_pred\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mview(X\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m),\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    401\u001B[0m     n_values \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m*\u001B[39mX\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/nlp2022-hw2-main/hw2/stud/modelCD.py:316\u001B[0m, in \u001B[0;36mCD_Model.forward\u001B[0;34m(self, X, X_len, segment_ids, y, predicate_position, attention_mask, around_predicate, ids)\u001B[0m\n\u001B[1;32m    315\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, X,X_len,segment_ids,y,predicate_position,attention_mask,around_predicate, ids):           \u001B[38;5;66;03m#TODO highligt the predicate\u001B[39;00m\n\u001B[0;32m--> 316\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbert\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msegment_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    317\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m2\u001B[39m]\n\u001B[1;32m    318\u001B[0m     token_embeddings \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack(hidden_states, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:1010\u001B[0m, in \u001B[0;36mBertModel.forward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1003\u001B[0m \u001B[38;5;66;03m# Prepare head mask if needed\u001B[39;00m\n\u001B[1;32m   1004\u001B[0m \u001B[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001B[39;00m\n\u001B[1;32m   1005\u001B[0m \u001B[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001B[39;00m\n\u001B[1;32m   1006\u001B[0m \u001B[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001B[39;00m\n\u001B[1;32m   1007\u001B[0m \u001B[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001B[39;00m\n\u001B[1;32m   1008\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[0;32m-> 1010\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membeddings\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1011\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1012\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1013\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1014\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1015\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1016\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1017\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(\n\u001B[1;32m   1018\u001B[0m     embedding_output,\n\u001B[1;32m   1019\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mextended_attention_mask,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1027\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m   1028\u001B[0m )\n\u001B[1;32m   1029\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:235\u001B[0m, in \u001B[0;36mBertEmbeddings.forward\u001B[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001B[0m\n\u001B[1;32m    232\u001B[0m         token_type_ids \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(input_shape, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mposition_ids\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m    234\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inputs_embeds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 235\u001B[0m     inputs_embeds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mword_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    236\u001B[0m token_type_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtoken_type_embeddings(token_type_ids)\n\u001B[1;32m    238\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m inputs_embeds \u001B[38;5;241m+\u001B[39m token_type_embeddings\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/torch/nn/modules/sparse.py:158\u001B[0m, in \u001B[0;36mEmbedding.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 158\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/torch/nn/functional.py:2183\u001B[0m, in \u001B[0;36membedding\u001B[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[1;32m   2177\u001B[0m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[1;32m   2178\u001B[0m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[1;32m   2179\u001B[0m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[1;32m   2180\u001B[0m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[1;32m   2181\u001B[0m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[1;32m   2182\u001B[0m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[0;32m-> 2183\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper__index_select)"
     ]
    }
   ],
   "source": [
    "#'''\n",
    "early_stopping = pl.callbacks.EarlyStopping(\n",
    "    monitor='val_f1',  # the value that will be evaluated to activate the early stopping of the model.\n",
    "    patience=5,  # the number of consecutive attempts that the model has to raise (or lower depending on the metric used) to raise the \"monitor\" value.\n",
    "    verbose=True,  # whether to log or not information in the console.\n",
    "    mode='max', # wheter we want to maximize (max) or minimize the \"monitor\" value.\n",
    ")\n",
    "\n",
    "check_point_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_f1',  # the value that we want to use for model selection.\n",
    "    verbose=True,  # whether to log or not information in the console.\n",
    "    save_top_k=1,  # the number of checkpoints we want to store.\n",
    "    mode='max',  # wheter we want to maximize (max) or minimize the \"monitor\" value.\n",
    "    filename='model_CD{epoch}-{val_f1:.4f}'  # the prefix on the checkpoint values. Metrics store by the trainer can be used to dynamically change the name.\n",
    ")\n",
    "\n",
    "\n",
    "cd_dm = SentencesDataModule(\n",
    "    data_train_path=EN_TRAIN_PATH,\n",
    "    data_dev_path=EN_DEV_PATH,\n",
    "    data_test_path=EN_DEV_PATH,\n",
    "    batch_size=16\n",
    ")\n",
    "cd_classifier = CD_Model(language=\"en\",p=0.5)\n",
    "# the PyTorch Lightning Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,  # maximum number of epochs.\n",
    "    gpus=1,  # the number of gpus we have at our disposal.\n",
    "    callbacks=[early_stopping, check_point_callback]  # the callback we want our trainer to use.\n",
    ")\n",
    "# and finally we can let the \"trainer\" fit the amazon reviews classifier.\n",
    "trainer.fit(model=cd_classifier, datamodule=cd_dm)\n",
    "model_path = \"../../model/modelCD.ckpt\"\n",
    "classifier = CD_Model.load_from_checkpoint(model_path,language=\"en\").to(device)\n",
    "\n",
    "\n",
    "\n",
    "sentences,labels = read_dataset(EN_DEV_PATH)\n",
    "\n",
    "\n",
    "for idx,key in enumerate(sentences):\n",
    "    prediction = cd_classifier.predict(sentences[key])[\"roles\"]\n",
    "    lab = labels[key][\"roles\"]\n",
    "    print(\"PREDICTED\",prediction)\n",
    "    print(\"GROUND TRUTH\",lab)\n",
    "\n",
    "#'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}